{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Task (XOR Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook a classification task based on the XOR function is presented. \n",
    "\n",
    "\n",
    "### The setup is the following:\n",
    "* We generate a data set containing two classes which are not linearly separable.\n",
    "* By the variable ``center_gap`` the overlap of the two classes can be modified.\n",
    "* We visualize the sampled data sets.\n",
    "* We train a linear classifier and evaluate the results.\n",
    "\n",
    "### Excercises\n",
    "* Exercise 1: Train a non-linear classifier and evaluate the results.\n",
    "* Exercise 2: Reduce the gap (``center_gap``) between the classes and evaluate on specificly selected samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from res.plot_lib import set_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default()\n",
    "seed = 44\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pytorch Device: GPU if available, else use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Notebook Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_gap = 9         # Distance between cluster centers of the data set\n",
    "num_samples = 2000     # Number of samples included in the data set\n",
    "num_of_classes = 2     # Number of classes in the data set\n",
    "validation_left_out = 0.2     # Fraction of data set used for validation\n",
    "\n",
    "H = 10                 # Number of hidden unites in the Neural Netowrk\n",
    "num_out = 1            # Number of outputs in the neural network (Binary classifier needs only one output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerate XOR Data Set with Four Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from 2 dimensinal normal distribution\n",
    "X = torch.normal(mean=0, std=1, size=(num_samples,2)) - 0.5 * center_gap\n",
    "\n",
    "# Sample cluster ids randomly from {0,1,2,3}\n",
    "cluster_id = torch.randint(low=0,high=4, size=(num_samples,))\n",
    "\n",
    "# Transform data point to receive four clusters\n",
    "#      odd cluster_id   -->  shift x value by center_gap\n",
    "#      cluster_id >= 2  -->  shift y value by center_gap\n",
    "X = torch.stack([X[:,0] + center_gap * (cluster_id % 2), \n",
    "                 X[:,1] + center_gap * (cluster_id // 2)], axis=-1)\n",
    "\n",
    "# Map cluster_ids to class labels: \n",
    "#      cluster_ids 0 and 3 --> 0\n",
    "#      cluster_ids 1 and 4 --> 1\n",
    "Y = torch.where((cluster_id == 0) + (cluster_id == 3) > 0, \n",
    "                torch.zeros_like(cluster_id), \n",
    "                torch.ones_like(cluster_id)).type(torch.FloatTensor)\n",
    "Y = torch.unsqueeze(Y, axis=-1)\n",
    "\n",
    "\n",
    "# Split data into training and validation set\n",
    "split_id = int(num_samples*validation_left_out)\n",
    "cluster_id_train = cluster_id[split_id:]\n",
    "X_train = X[split_id:]\n",
    "Y_train = Y[split_id:]\n",
    "cluster_id_val = cluster_id[:split_id]\n",
    "X_val = X[:split_id]\n",
    "Y_val = Y[:split_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data Set Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", tuple(X_train.size()))\n",
    "print(\"Y_train:\", tuple(Y_train.size()))\n",
    "print(\"Cluster Ids Training:\", torch.unique(cluster_id_train,return_counts=True))\n",
    "print(\"X_val:  \", tuple(X_val.size()))\n",
    "print(\"Y_val:  \", tuple(Y_val.size()))\n",
    "print(\"Cluster Ids Validation:\", torch.unique(cluster_id_val,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Plot Training Data\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.scatter(X_train.cpu()[Y_train[:,0]==0,0].numpy(), X_train.cpu()[Y_train[:,0]==0,1].numpy(), color=\"green\", label=\"Class 1\")\n",
    "plt.scatter(X_train.cpu()[Y_train[:,0]==1,0].numpy(), X_train.cpu()[Y_train[:,0]==1,1].numpy(), color=\"yellow\", label=\"Class 2\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.axis('equal');\n",
    "plt.title('Training Data');\n",
    "\n",
    "# Plot Validation Data\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.scatter(X_val.cpu()[Y_val[:,0]==0,0].numpy(), X_val.cpu()[Y_val[:,0]==0,1].numpy(), color=\"green\", label=\"Class 1\")\n",
    "plt.scatter(X_val.cpu()[Y_val[:,0]==1,0].numpy(), X_val.cpu()[Y_val[:,0]==1,1].numpy(), color=\"yellow\", label=\"Class 2\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.axis('equal');\n",
    "plt.title('Validation Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier\n",
    "\n",
    "For the linear classifier, we train 5 networks and visualize the predictions of the validation data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "* Train ``num_networks`` different networks.\n",
    "* Train for ``max_epochs`` epochs.\n",
    "* Set the leanrning rate of the optimizer to ``learning_rate``.\n",
    "* Use the binary-cross-entropy as loss function ``torch.nn.BCELoss()``.\n",
    "\n",
    "* Save the trained models into the list ``models``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3            # Learning rate for the optimizer\n",
    "max_epochs  = 250                # Maximum number of epochs to train\n",
    "num_networks = 5                 # Number of networks to be trained\n",
    "criterion = torch.nn.BCELoss()   # Use binary-cross-entropy as loss function\n",
    "\n",
    "models = []                      # Empty list to be filled with trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network without Non-Linearities\n",
    "* We use the ``nn`` package to create our linear model.\n",
    "* The network consists of ``H`` hidden units.\n",
    "* Each linear module has a weight and bias.\n",
    "* We apply ``nn.Sigmoid()`` function to output in order to receive a probability value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_linear():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, H),\n",
    "        nn.Linear(H, 1),\n",
    "        nn.Sigmoid()      # Sigmoid function to receive probabilities\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(build_model_linear())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network without Non-Linearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_networks(max_epochs, num_networks, X, y, model_generator):\n",
    "\n",
    "    models = []\n",
    "\n",
    "    # Iterate through number of networks\n",
    "    for n in range(num_networks):\n",
    "\n",
    "        torch.manual_seed(seed + n+3);\n",
    "        model = model_generator()\n",
    "        model.to(device)       # move model to device\n",
    "        models.append(model)\n",
    "\n",
    "        # we use the optim package to apply\n",
    "        # stochastic gradient descent for our parameter updates\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)   \n",
    "\n",
    "        for t in range(max_epochs):\n",
    "\n",
    "            # Feed forward to get prediction\n",
    "            y_pred_prob = model(X)\n",
    "\n",
    "            # Compute the loss (Binary-Cross-Entropy)\n",
    "            loss = criterion(y_pred_prob, y)\n",
    "\n",
    "            # Print current progress\n",
    "            print(\"[MODEL]: %i, [EPOCH]: %i, [LOSS]: %.6f\" % (n+1, t, loss.item()))\n",
    "\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "            # zero the gradients before running the backward pass.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass to compute the gradient of loss w.r.t our learnable params. \n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "    return models\n",
    "            \n",
    "models = train_networks(max_epochs, num_networks, X_train, Y_train, model_generator=build_model_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Predictions of Validation Set for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(models, X_val, Y_val):\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    rows =2\n",
    "    columns = 5\n",
    "\n",
    "    for i, m in enumerate(models):\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "    \n",
    "        y_pred = torch.round(m(X_val))\n",
    "\n",
    "        plt.scatter(X_val.cpu()[y_pred[:,0]==1, 0].numpy(), X_val.cpu()[y_pred[:,0]==1, 1].numpy(), color=\"green\")\n",
    "        plt.scatter(X_val.cpu()[y_pred[:,0]==0, 0].numpy(), X_val.cpu()[y_pred[:,0]==0, 1].numpy(), color=\"yellow\")\n",
    "        plt.axis('equal')\n",
    "        plt.title('Model %i \\n Acc.: %.2f\\n Loss: %.2f' %(i+1, \n",
    "                                                  torch.sum(torch.round(y_pred) \n",
    "                                                            == Y_val) / len(y_pred),\n",
    "                                                  criterion(y_pred, Y_val)))   \n",
    "\n",
    "predict_and_plot(models, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excercises\n",
    "===========\n",
    "* Exercise 1: Train a non-linear classifier and evaluate the results.\n",
    "* Exercise 2: Reduce the gap (``center_gap``) between the classes and evaluate on specificly selected samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Two-Layered Non-Linear Network\n",
    "\n",
    "In this excercise you extend the above presented examples to a non-linear classifier. This can be realized by adding different non-linearities to the model description (e.g. ``nn.Tanh()`` or ``nn.ReLU``).\n",
    "\n",
    "Go through the code below and fill the missing parts by parts (marked as ``???``) such that...\n",
    "* ... a nonlinearity is applied by adding ``nn.ReLU()`` to the network architecture.\n",
    "* ... 5 networks are trained.\n",
    "* ... the network is trained for 200 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "max_epochs  = ???                # Maximum number of epochs to train\n",
    "num_networks = ???               # Number of networks to be trained\n",
    "models = []                      # Empty list to be filled with trained models\n",
    "criterion = torch.nn.BCELoss()   # Use binary-cross-entropy as loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network with Non-Linearities\n",
    "* Use nn package to create our linear model\n",
    "* The network consists of ``H`` hidden units\n",
    "* Each Linear module has a weight and bias\n",
    "* Apply sigmoid on output to receive a probability value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, H),\n",
    "        ???\n",
    "        nn.Linear(H, H),\n",
    "        ???\n",
    "        nn.Linear(H, 1),\n",
    "        nn.Sigmoid()      # Sigmoid function to receive probabilities\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(build_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network with Non-Linearities\n",
    "* Train ``num_networks`` different networks.\n",
    "* Use the binary-cross-entropy as loss function ``torch.nn.BCELoss()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = train_networks(max_epochs, num_networks, X_train, Y_train, model_generator=build_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Predictions of Validation Set for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(models, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Reduced Gap between Cluster Centers\n",
    "\n",
    "In this excercise we reduce the gap between the single clusters by setting ``center_gap``. Based on this we generate new data and train models. Following, we evaluate the model performance in uncertain regions of the data plane. \n",
    "\n",
    "Go through the code below and fill the missing parts by parts (marked as '???') such that \n",
    "* the ``center_gap`` is set to a smaller values (as for example 3).\n",
    "* the model is evaluated on interesting inputs after training ``(eval_point_1,eval_point_2,eval_point_3,eval_point_4)``. You might use ``[0,0], [-2,-2], [-2,2] and [0, 10]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_gap = ???              # Distance between cluster centers of the data set\n",
    "num_samples = 2000            # Number of samples included in the data set\n",
    "num_of_classes = 2            # Number of classes in the data set\n",
    "validation_left_out = 0.2     # Fraction of data set used for validation\n",
    "\n",
    "H = 10                        # Number of hidden unites in the Neural Netowrk\n",
    "num_out = 1                   # Number of outputs in the neural network (Binary classifier needs only one output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerate XOR Data Set with Four Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from 2 dimensinal normal distribution\n",
    "X = torch.normal(mean=0, std=1, size=(num_samples,2)) - 0.5 * center_gap\n",
    "\n",
    "# Sample cluster ids randomly from {0,1,2,3}\n",
    "cluster_id = torch.randint(low=0,high=4, size=(num_samples,))\n",
    "\n",
    "# Transform data point to receive four clusters\n",
    "#      odd cluster_id   -->  shift x value by center_gap\n",
    "#      cluster_id >= 2  -->  shift y value by center_gap\n",
    "X = torch.stack([X[:,0] + center_gap * (cluster_id % 2), \n",
    "                 X[:,1] + center_gap * (cluster_id // 2)], axis=-1)\n",
    "\n",
    "# Map cluster_ids to class labels: \n",
    "#      cluster_ids 0 and 3 --> 0\n",
    "#      cluster_ids 1 and 4 --> 1\n",
    "Y = torch.where((cluster_id == 0) + (cluster_id == 3) > 0, \n",
    "                torch.zeros_like(cluster_id), \n",
    "                torch.ones_like(cluster_id)).type(torch.FloatTensor)\n",
    "Y = torch.unsqueeze(Y, axis=-1)\n",
    "\n",
    "\n",
    "# Split data into training and validation set\n",
    "split_id = int(num_samples*validation_left_out)\n",
    "cluster_id_train = cluster_id[split_id:]\n",
    "X_train = X[split_id:]\n",
    "Y_train = Y[split_id:]\n",
    "cluster_id_val = cluster_id[:split_id]\n",
    "X_val = X[:split_id]\n",
    "Y_val = Y[:split_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data Set Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes:\")\n",
    "print(\"X_train:\", tuple(X_train.size()))\n",
    "print(\"Y_train:\", tuple(Y_train.size()))\n",
    "print(\"Cluster Ids Training:\", torch.unique(cluster_id_train,return_counts=True))\n",
    "print(\"X_val:  \", tuple(X_val.size()))\n",
    "print(\"Y_val:  \", tuple(Y_val.size()))\n",
    "print(\"Cluster Ids Validation:\", torch.unique(cluster_id_val,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Plot Training Data\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.scatter(X_train.cpu()[Y_train[:,0]==0,0].numpy(), X_train.cpu()[Y_train[:,0]==0,1].numpy(), color=\"green\", label=\"Class 1\")\n",
    "plt.scatter(X_train.cpu()[Y_train[:,0]==1,0].numpy(), X_train.cpu()[Y_train[:,0]==1,1].numpy(), color=\"yellow\", label=\"Class 2\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.axis('equal');\n",
    "plt.title('Training Data');\n",
    "\n",
    "# Plot Validation Data\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.scatter(X_val.cpu()[Y_val[:,0]==0,0].numpy(), X_val.cpu()[Y_val[:,0]==0,1].numpy(), color=\"green\", label=\"Class 1\")\n",
    "plt.scatter(X_val.cpu()[Y_val[:,0]==1,0].numpy(), X_val.cpu()[Y_val[:,0]==1,1].numpy(), color=\"yellow\", label=\"Class 2\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.axis('equal');\n",
    "plt.title('Validation Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(2, H),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(H, H),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(H, 1),\n",
    "        nn.Sigmoid()      # Sigmoid function to receive probabilities\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(build_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "max_epochs  = 300                # Maximum number of epochs to train\n",
    "num_networks = 5                 # Number of networks to be trained\n",
    "models = []                      # Empty list to be filled with trained models\n",
    "criterion = torch.nn.BCELoss()   # Use binary-cross-entropy as loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network\n",
    "* Train ``num_networks`` different networks.\n",
    "* Use the binary-cross-entropy as loss function ``torch.nn.BCELoss()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_networks(max_epochs, num_networks, X_train, Y_train, model_generator=build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Predictions of Validation Set for each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(models, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Specific Inputs\n",
    "\n",
    "Based on the plots shown above, define four points to predict. Which points might be interesting and what is your expectation on the model behaviour? You might also use the four points given in the introduction of this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_point_1 = ???\n",
    "eval_point_2 = ???\n",
    "eval_point_3 = ???\n",
    "eval_point_4 = ???\n",
    "\n",
    "eval_points = torch.Tensor([eval_point_1, eval_point_2, eval_point_3, eval_point_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = models[0](eval_points.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print predicted Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(eval_points)):\n",
    "    print(\"Evaluation Point: \" + str(eval_points[i].numpy()) + \"\\n\"\n",
    "          \"    Class 1: \" + str(torch.round(predictions[i] * 100).item() / 100) + \"\\n\" +\n",
    "          \"    Class 1: \" + str(torch.round((1-predictions[i]) * 100).item() / 100) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
